# From-GCS-to-BigQuery
Automated ELT Data Processing Using GCP, BigQuery, and Airflow

This project demonstrates how to build an efficient ELT data pipeline to process 1 million records using Google Cloud Platform (GCP) and Apache Airflow. The tutorial provides hands-on guidance for loading data from Google Cloud Storage (GCS) into BigQuery, transforming the data, and creating country-specific tables and views. It focuses on utilizing modern ELT (Extract, Load, Transform) concepts to build scalable, efficient data workflows for processing large datasets.

Key Features

Data Extraction: Extract data from GCS.

Data Loading: Load data into BigQuery for further processing and analysis.

Data Transformation: Transform data by applying necessary operations and filtering.

Country-Specific Views: Create tables and views for each country to facilitate targeted analysis.

Apache Airflow Automation: Automate and schedule the ELT pipeline using Apache Airflow, making the data pipeline more efficient and scalable.

Scalable Processing: Handle and process large volumes of data, ensuring it is scalable and can handle up to 1 million records.


![image](https://github.com/user-attachments/assets/79a6ba39-6b1d-45d3-a6c1-985f71bd62db)

Conclusion

This project provides an end-to-end solution for building an efficient ELT data pipeline on GCP, with automation and orchestration via Apache Airflow
